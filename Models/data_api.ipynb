{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe73752c-4f01-4953-a3c7-f18c4a05e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29b8e1fc-b908-42e2-8175-b2c9419bc085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d920394d-ea67-4150-ba88-6ab3451a942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ebe1079-6744-410f-a807-cf7f19e1c598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f354431b-cb56-4bcb-849b-6b1aafe2dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f613ad48-9cb5-4225-9a9c-88400f55bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat(3).batch(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d10ae200-b319-44ba-85bc-55d7e6144de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34522d38-1426-4d39-968e-f2b9427159ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dca5ec17-f485-4139-97b0-61a66c1389fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95f377aa-b2e4-4731-babb-c2f2a9e6fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.apply(tf.data.experimental.unbatch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b07add0-8b65-4478-baba-b33e20974a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3305017-9353-447d-99a4-4cba01cb77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af69418a-a473-42cb-8606-ab78f794d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "042eee08-596a-4297-a411-2ce536d86ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f6f7433-a11f-442c-a435-35eba98e3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d19c831a-8ab2-40d2-ad5e-404c89c5bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf3bdaa0-1b80-4b74-8127-1784c5e04a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5318541-2b27-41e5-8553-140760078318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target.reshape(-1, 1), test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac827678-b94e-4428-b35e-94ffd2bfeba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf3ce560-4827-4064-b900-102587c193f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58fe544c-12ce-4e56-b439-17f4ace96233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05e9e51a-576a-43c1-9fd4-9b5c08de7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7da7bed-ef42-4d97-bede-42cf25b11021",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bf7ce82-c191-4306-9e76-67da8ae3ce19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.88571846e+00,  2.86247578e+01,  5.41938958e+00,  1.09094440e+00,\n",
       "        1.42403900e+03,  3.10614872e+00,  3.56298337e+01, -1.19563951e+02])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a18eda70-0041-4d9c-a35d-954909a47a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91994379e+00, 1.25925683e+01, 2.03325782e+00, 3.49308722e-01,\n",
       "       1.13253004e+03, 1.22456163e+01, 2.12216649e+00, 1.99991425e+00])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99490976-8ace-4a1a-8a26-66426a517b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a0ecad3-e509-4a36-9f71-ec6291b11787",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0111438e-307e-4a3b-bb35-52af1407bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.7308</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.048611</td>\n",
       "      <td>1.084722</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>3.015278</td>\n",
       "      <td>33.95</td>\n",
       "      <td>-118.10</td>\n",
       "      <td>1.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5707</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.489796</td>\n",
       "      <td>0.955782</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>38.01</td>\n",
       "      <td>-122.03</td>\n",
       "      <td>1.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8304</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.040302</td>\n",
       "      <td>0.977330</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>3.680101</td>\n",
       "      <td>34.09</td>\n",
       "      <td>-118.04</td>\n",
       "      <td>1.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0286</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.390071</td>\n",
       "      <td>1.085106</td>\n",
       "      <td>753.0</td>\n",
       "      <td>2.670213</td>\n",
       "      <td>33.96</td>\n",
       "      <td>-118.41</td>\n",
       "      <td>3.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0909</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.360902</td>\n",
       "      <td>1.075188</td>\n",
       "      <td>466.0</td>\n",
       "      <td>3.503759</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-118.12</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.7308      34.0  5.048611   1.084722      2171.0  3.015278     33.95   \n",
       "1  4.5707      27.0  5.489796   0.955782      1666.0  2.833333     38.01   \n",
       "2  3.8304      34.0  5.040302   0.977330      1461.0  3.680101     34.09   \n",
       "3  6.0286      44.0  6.390071   1.085106       753.0  2.670213     33.96   \n",
       "4  3.0909      27.0  4.360902   1.075188       466.0  3.503759     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -118.10             1.969  \n",
       "1    -122.03             1.759  \n",
       "2    -118.04             1.830  \n",
       "3    -118.41             3.560  \n",
       "4    -118.12             1.875  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4e43b33-55ff-44a8-ae7a-6dcc16b7316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets\\\\housing\\\\my_train_00.csv',\n",
       " 'datasets\\\\housing\\\\my_train_01.csv',\n",
       " 'datasets\\\\housing\\\\my_train_02.csv',\n",
       " 'datasets\\\\housing\\\\my_train_03.csv',\n",
       " 'datasets\\\\housing\\\\my_train_04.csv',\n",
       " 'datasets\\\\housing\\\\my_train_05.csv',\n",
       " 'datasets\\\\housing\\\\my_train_06.csv',\n",
       " 'datasets\\\\housing\\\\my_train_07.csv',\n",
       " 'datasets\\\\housing\\\\my_train_08.csv',\n",
       " 'datasets\\\\housing\\\\my_train_09.csv',\n",
       " 'datasets\\\\housing\\\\my_train_10.csv',\n",
       " 'datasets\\\\housing\\\\my_train_11.csv',\n",
       " 'datasets\\\\housing\\\\my_train_12.csv',\n",
       " 'datasets\\\\housing\\\\my_train_13.csv',\n",
       " 'datasets\\\\housing\\\\my_train_14.csv',\n",
       " 'datasets\\\\housing\\\\my_train_15.csv',\n",
       " 'datasets\\\\housing\\\\my_train_16.csv',\n",
       " 'datasets\\\\housing\\\\my_train_17.csv',\n",
       " 'datasets\\\\housing\\\\my_train_18.csv',\n",
       " 'datasets\\\\housing\\\\my_train_19.csv']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6d832ca-7ef0-4ed4-ae34-356be4155aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is my first record\")\n",
    "    f.write(b\"And this is my second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42af56f2-0bba-4622-a176-33233e98ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths= [\"my_data.tfrecord\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c977f19-fac4-455a-ab94-8c47d4ceb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c1a00e2-0906-4a2b-bceb-9bc03aeb85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is my first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is my second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0750dab8-4107-4e47-adf4-b84d00d66248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5220ae39-f08e-4d13-bd39-a303d6761f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ef81b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train_full[5000:], X_train_full[:5000]\n",
    "y_train, y_valid = y_train_full[5000:], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9ec5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e67df76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return Example(\n",
    "    features=Features(\n",
    "    feature={\n",
    "        \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "        \"label\": Feature(int64_list= Int64List(value=[label])),\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7af6e59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.train import Example, Features, Feature, BytesList, Int64List\n",
    "\n",
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d174a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6832b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c97d1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0425fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example=tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image=tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image=tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa35f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf019ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bfe1052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6eb01b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "412b0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_)/(self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7ef1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = Standardization(input_shape=[28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8240ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()), axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86820d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization.adapt(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bbca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
